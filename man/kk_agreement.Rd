% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/advanced_epi.R
\name{kk_agreement}
\alias{kk_agreement}
\title{Inter-Rater Agreement (KK)}
\usage{
kk_agreement(data, rater1, rater2, weights = "unweighted", conf.level = 0.95)
}
\arguments{
\item{data}{Data frame}

\item{rater1}{First rater's ratings}

\item{rater2}{Second rater's ratings}

\item{weights}{Weighting scheme: "unweighted" (default), "linear", or "quadratic"}

\item{conf.level}{Confidence level (default 0.95)}
}
\value{
Tibble with kappa statistics and confidence intervals
}
\description{
Calculates inter-rater agreement measures including Cohen's Kappa,
Weighted Kappa, and Prevalence-Adjusted Bias-Adjusted Kappa (PABAK).
}
\examples{
data <- data.frame(
              rater1 = c(1, 0, 1, 0, 1),
              rater2 = c(1, 1, 0, 0, 1)
)
kk_agreement(data, rater1, rater2)

}
